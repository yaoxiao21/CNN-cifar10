{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home 3: Build a CNN for image recognition.\n",
    "\n",
    "### Name: Yao Xiao\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read, complete, and run my code.\n",
    "\n",
    "2. **Make substantial improvements** to maximize the accurcy.\n",
    "    \n",
    "3. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "    \n",
    "4. Upload this .HTML file to your Github repo.\n",
    "\n",
    "4. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583A-2019Spring/blob/master/homework/HM3/cnn.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(np.max(y_train) - np.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    result = np.zeros((len(y), num_class))\n",
    "    for i,label in enumerate(y):\n",
    "        result[i,label]=1\n",
    "    return result\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = np.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark: \n",
    "\n",
    "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
    "* Add more layers.\n",
    "* Use regularizations, e.g., dropout.\n",
    "* Use batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 545,098\n",
      "Trainable params: 545,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "learning_rate = 1E-5 # to be tuned!\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 36s 905us/step - loss: 8.2007 - acc: 0.2073 - val_loss: 6.0026 - val_acc: 0.2574\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 39s 964us/step - loss: 4.9410 - acc: 0.2873 - val_loss: 3.8768 - val_acc: 0.3012\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 39s 970us/step - loss: 3.2000 - acc: 0.3265 - val_loss: 2.9092 - val_acc: 0.3352\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 39s 972us/step - loss: 2.5738 - acc: 0.3583 - val_loss: 2.5102 - val_acc: 0.3596\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 39s 975us/step - loss: 2.2260 - acc: 0.3864 - val_loss: 2.2198 - val_acc: 0.3835\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 39s 982us/step - loss: 1.9925 - acc: 0.4120 - val_loss: 2.0284 - val_acc: 0.4045\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 39s 986us/step - loss: 1.8287 - acc: 0.4350 - val_loss: 1.9118 - val_acc: 0.4209\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 40s 988us/step - loss: 1.7027 - acc: 0.4558 - val_loss: 1.8244 - val_acc: 0.4326\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 40s 990us/step - loss: 1.6063 - acc: 0.4773 - val_loss: 1.7604 - val_acc: 0.4481\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 40s 993us/step - loss: 1.5326 - acc: 0.4964 - val_loss: 1.7101 - val_acc: 0.4630\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_tr, y_tr, batch_size=32, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,150,410\n",
      "Trainable params: 1,148,938\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "model1 = Sequential()\n",
    "model1.add(layers.Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "model1.add(layers.BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(layers.MaxPooling2D((2, 2)))\n",
    "model1.add(layers.Conv2D(64, (3, 3), padding='same'))\n",
    "model1.add(layers.BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(layers.MaxPooling2D((2, 2)))\n",
    "model1.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "model1.add(layers.BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(layers.MaxPooling2D((2, 2)))\n",
    "model1.add(layers.Flatten())\n",
    "model1.add(layers.Dropout(0.5))\n",
    "model1.add(layers.Dense(512))\n",
    "model1.add(layers.BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "learning_rate = 3E-4 # to be tuned!\n",
    "model1.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=learning_rate), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 132s 3ms/step - loss: 1.4575 - acc: 0.4771\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 129s 3ms/step - loss: 1.1073 - acc: 0.6070\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 129s 3ms/step - loss: 0.9777 - acc: 0.6540\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 127s 3ms/step - loss: 0.8880 - acc: 0.6880\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 118s 2ms/step - loss: 0.8225 - acc: 0.7113\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 119s 2ms/step - loss: 0.7734 - acc: 0.7268\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 129s 3ms/step - loss: 0.7264 - acc: 0.7449\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.6924 - acc: 0.7574\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.6564 - acc: 0.7680\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.6276 - acc: 0.7795\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.5939 - acc: 0.7916\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.5707 - acc: 0.7979\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.5450 - acc: 0.8064\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.5189 - acc: 0.8189\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.5037 - acc: 0.8240\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.4829 - acc: 0.8293\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.4656 - acc: 0.8364\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.4479 - acc: 0.8422\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.4309 - acc: 0.8477\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.4112 - acc: 0.8557\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.3950 - acc: 0.8595\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.3857 - acc: 0.8655\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.3663 - acc: 0.8716\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.3550 - acc: 0.8746\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.3447 - acc: 0.8797\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.3318 - acc: 0.8845\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.3163 - acc: 0.8890\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.3040 - acc: 0.8943\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 132s 3ms/step - loss: 0.2946 - acc: 0.8971\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 132s 3ms/step - loss: 0.2850 - acc: 0.9015\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.2712 - acc: 0.9059\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.2618 - acc: 0.9080\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.2536 - acc: 0.9108\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.2502 - acc: 0.9133\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.2386 - acc: 0.9182\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 119s 2ms/step - loss: 0.2310 - acc: 0.9193\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 123s 2ms/step - loss: 0.2251 - acc: 0.9211\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.2164 - acc: 0.9245\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.2133 - acc: 0.9263\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.2024 - acc: 0.9292\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.1999 - acc: 0.9303\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.1955 - acc: 0.9320\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.1895 - acc: 0.9334\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.1812 - acc: 0.9374\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 132s 3ms/step - loss: 0.1753 - acc: 0.9394\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 132s 3ms/step - loss: 0.1729 - acc: 0.9402\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.1651 - acc: 0.9431\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.1638 - acc: 0.9433\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 190s 4ms/step - loss: 0.1593 - acc: 0.9452\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 132s 3ms/step - loss: 0.1594 - acc: 0.9447\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(x_train, y_train_vec, batch_size=128, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 471us/step\n",
      "loss = 0.6779227051258088\n",
      "accuracy = 0.8011\n"
     ]
    }
   ],
   "source": [
    "loss_and_acc = model1.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
